# Note that we use `threads` here as SLURM `--cpus-per-task`.
cluster: >-
  sbatch --time={resources.time}
  --mem={resources.mem}
  $(if [[ '{resources.account}' ]]; then echo '-A {resources.account}'; fi)
  $(if [[ '{resources.partition}' ]]; then echo '-p {resources.partition}'; fi)
  -N {resources.nodes}
  -n {resources.tasks_per_node}
  -c {threads}
  -o logs/{rule}-{wildcards}.out -e logs/{rule}-{wildcards}.err
  $(if [[ '{resources.qos}' ]]; then echo '-q {resources.qos}'; fi)
  $(if [[ '{resources.gres}' ]]; then echo '--gres={resources.gres}'; fi)
cluster-cancel: slurm-cancel
jobs: 50
default-resources: ["time='00:15:00'", "mem='4G'", "nodes=1", "tasks_per_node=1", "extra=''", "gres=''", "qos=''", "account=''"]
use-conda: true
use-envmodules: true
